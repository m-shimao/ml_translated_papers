{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 論文和訳: Deep Residual Learning for Image Recognition\n",
    "\n",
    "## Abstract\n",
    "\n",
    "より深いニューラルネットワークは訓練することがより困難です。\n",
    "\n",
    "これまでに使用されていたものよりもかなり深いネットワークのトレーニングを容易にするために、`residual learning framework` を提示します。\n",
    "\n",
    "非参照関数を学習するのではなく、レイヤ入力を参照して残差関数を学習するようにレイヤを明示的に再構成する。\n",
    "\n",
    "我々は、これらの`residual network` がより容易に最適化され、かなり深い深度から精度を得ることができるという包括的な経験的証拠を提供する。\n",
    "\n",
    "ImageNetデータセットでは、VGGネットよりも深い8×15の深さの残留ネットを評価しますが、それでも複雑さは低くなります。\n",
    "\n",
    "これらの残差ネットのアンサンブルは、ImageNetテストセットで3.57％のエラーを達成します。\n",
    "\n",
    "この結果は、ILSVRC 2015分類作業の第1位を獲得しました。\n",
    "\n",
    "我々はまた、100および1000層のCIFAR-10に関する分析を提示する。\n",
    "\n",
    "表現の深さは、多くの視覚的認識課題にとって重要である。\n",
    "\n",
    "私たちの非常に深い表現のために、私たちはCOCOオブジェクト検出データセットで28％の相対的な改善を得ています。\n",
    "\n",
    "`Deep residual nets` は、ILSVRC＆COCO 2015の競技会1への提出の基礎であり、\n",
    "\n",
    "ImageNet検出、ImageNetローカリゼーション、COCO検出、およびCOCOセグメンテーションの第1位を獲得しました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Introduction\n",
    "\n",
    "深い畳み込みニューラルネットワーク[22、21]は、画像分類のための一連のブレークスルーを導いた[21,50,40]。\n",
    "\n",
    "ディープネットワークは、低/中/高レベルの特徴[50]とエンドツーエンドの多層形式における分類と自然に統合し、\n",
    "\n",
    "特徴の \"レベル\"を積み重ねられたレイヤの数（深さ）で強化することができます。\n",
    "\n",
    "最近の証拠[41,44]は、ネットワークの深さが非常に重要であることを示しており、\n",
    "\n",
    "困難なImageNetデータセット[36]の主要な結果[41]、[44]、[13] 16の深さ[41] ~30 [16]。\n",
    "\n",
    "多くの他の重要でない視覚認識タスク[8,12,7,32,27]は、非常に深いモデルから大きな利益を得ている。\n",
    "\n",
    "深さの重要性を踏まえて、より多くのレイヤーを積み重ねるほど簡単にネットワークを学習することができますか？\n",
    "\n",
    "この質問に答える障害は、最初から収束を妨げる、消滅/爆発勾配の悪名高い問題であった[1,9]。\n",
    "\n",
    "しかし、この問題は、数十層のネットワークが逆伝播を伴う確率的勾配降下（SGD）の収束を開始することを可能にする\n",
    "\n",
    "正規化初期化[23,9,37,13]および中間正規化層[16] ]。\n",
    "\n",
    "より深いネットワークが収束を開始できるようになると、劣化の問題が明らかになりました。\n",
    "\n",
    "ネットワークの深さが深くなると、精度は飽和してしまいます（これは驚異的かもしれません）。\n",
    "\n",
    "予期しないことに、このような劣化は過補正によって引き起こされるものではなく、\n",
    "\n",
    "適切な深いモデルに層を追加すると、[11、42]で報告されているように、トレーニング誤差が大きくなり、\n",
    "\n",
    "代表的な例を図1に示す。\n",
    "\n",
    "学習効率の低下は、すべてのシステムが同様に容易に最適化できるわけではないことを示しています。\n",
    "\n",
    "より浅いアーキテクチャと、より多くのレイヤを追加する深い対応を考えてみましょう。\n",
    "\n",
    "より深いモデルへの構築による解決策が存在する。追加された層はアイデンティティマッピングであり、他の層は学習された浅いモデルからコピーされる。\n",
    "\n",
    "この構築された解の存在は、より深いモデルが、より浅いモデルよりも高い訓練エラーを生成してはならないことを示す。\n",
    "\n",
    "しかし、実験では、現在のソルバーが、構築されたソリューションと同等か\n",
    "\n",
    "それ以上の優れたソリューションを見つけることができないことを示しています（実現可能な時間にそうすることはできません）。\n",
    "\n",
    "本稿では、深い残存学習フレームワークを導入して劣化問題に取り組む。\n",
    "\n",
    "少数の積み重ねられた各層が所望の基礎となるマッピングに直接適合することを期待する代わりに、これらの層を残差マッピングに明示的に適合させる。\n",
    "\n",
    "正式には、所望の基礎となる写像をH（x）と表すと、積み重なった非線形層をF（x）：= H（x）-xの別の写像に適合させる。\n",
    "\n",
    "元の写像はF（x）+ xに再構築されます。\n",
    "\n",
    "元の参照されていないマッピングを最適化するよりも残差マッピングを最適化する方が簡単であると仮定します。\n",
    "\n",
    "極端な場合、アイデンティティマッピングが最適であれば、非線形レイヤのスタックによるアイデンティティマッピングを適合させるよりも、残差をゼロにプッシュする方が\n",
    "簡単です。\n",
    "\n",
    "F（x）+ xの定式化は、「ショートカット接続」を持つフィードフォワードニューラルネットワークによって実現することができる（図2）。\n",
    "\n",
    "ショートカット接続[2、34、49]は、1つまたは複数のレイヤーをスキップするものです。\n",
    "\n",
    "我々の場合、ショートカット接続は単純にアイデンティティマッピングを実行し、その出力は積み重ねられた層の出力に加えられる（図2）。\n",
    "\n",
    "アイデンティティのショートカット接続は、余分なパラメータも計算上の複雑さも追加しません。\n",
    "\n",
    "ネットワーク全体は、逆伝播を伴うSGDによってエンドツーエンドで訓練され、ソルバを変更することなく共通ライブラリ（例えば、Caffe [19]）を使用して容易に実装する\n",
    "ことができる。\n",
    "\n",
    "我々は、劣化問題を示すためにImageNet [36]に関する包括的な実験を行い、我々の方法を評価する。\n",
    "\n",
    "1）非常に深い残留ネットは最適化が容易ですが、相手の「プレーン」ネット（単純に積み重ねたレイヤー）は深度が増すと訓練エラーが高くなります。\n",
    "\n",
    "2）私たちの深い残差ネットは、深度が大幅に増えることで容易に精度を向上させることができ、結果は従来のネットワークよりも大幅に向上します。\n",
    "\n",
    "同様の現象がCIFAR-10セット[20]にも示されており、最適化の困難さと本発明の方法の効果が特定のデータセットに似ているわけではないことを示唆している。\n",
    "\n",
    "このデータセットでは、100以上のレイヤーで訓練されたモデルを正常に提示し、1000以上のレイヤーを持つモデルを探索します。\n",
    "\n",
    "ImageNet分類データ[36]では、極めて深い残差ネットによる優れた結果が得られます。\n",
    "\n",
    "私たちの152層の残存ネットは、ImageNet上でこれまでに発表された最も深いネットワークですが、VGGネットよりも複雑さは低くなっています[41]。\n",
    "\n",
    "私たちのアンサンブルは、ImageNetテストセットで3.57％のトップ5エラーを抱え、ILSVRC 2015分類競技会で1位を獲得しました。\n",
    "\n",
    "また、ILSVRC＆COCO 2015の競技では、ImageNet検出、ImageNetローカリゼーション、COCO検出、COCOセグメンテーションなど、第1位を獲得しました。\n",
    "\n",
    "この強力な証拠は、残存学習原理が一般的であることを示しており、他の視覚および非視覚の問題に適用可能であると我々は期待している。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Related Work\n",
    "\n",
    "### Residual Representations.(残余表現)\n",
    "\n",
    "画像認識では、VLAD [18]は辞書に対して残差ベクトルで符号化する表現であり、\n",
    "Fisher Vector [30]はVLADの確率的バージョン[18]として定式化することができる。\n",
    "\n",
    "両方とも、画像検索と分類のための強力な浅い表現である[4、48]。\n",
    "\n",
    "ベクトル量子化では、符号化残差ベクトル[17]は、元のベクトルを符号化するよりも効果的であることが示されている。\n",
    "\n",
    "部分微分方程式（PDEs）を解くための低レベルのビジョンとコンピュータグラフィックスでは、広く使用されているMultigrid法[3]は、\n",
    "各サブ問題がより粗いものとより細かいものの間の残留解を担う複数のスケールでサブ問題としてシステムを再定式化する規模。\n",
    "\n",
    "Multigridの代替案は、階層ベースの事前調整であり、2つのスケール間の残差ベクトルを表す変数に依存している[45,46]。\n",
    "\n",
    "これらのソルバーは、ソリューションの残りの性質を認識していない標準ソルバーよりもはるかに速く収束することが[3、45、46]示されています。\n",
    "\n",
    "これらの方法は、良好な再調整またはプレコンディショニングが最適化を単純化できることを示唆している。\n",
    "\n",
    "### Shortcut Connections.\n",
    "\n",
    "ショートカット接続につながるプラクティスと理論[2、34、49]は長い間研究されてきた。\n",
    "\n",
    "多層パーセプトロン（MLP）の訓練の初期の実践は、ネットワーク入力から出力に接続された線形層を追加することである[34,49]。\n",
    "\n",
    "[44,24]では、いくつかの中間層が消失/爆発勾配に対処するために補助分類器に直接接続されている。\n",
    "\n",
    "[39,38,31,47]の論文は、ショートカット接続によって実装された、層の応答、勾配、および伝搬された誤差をセンタリングする方法を提案している。\n",
    "\n",
    "[44]において、「開始」層は、ショートカットブランチとより深いブランチで構成されています。\n",
    "\n",
    "我々の研究と並行して、「高速道路ネットワーク」[42,43]は、ゲーティング機能とのショートカット接続を提示している[15]。\n",
    "\n",
    "これらのゲートは、パラメータに依存しないIDショートカットとは異なり、データに依存し、パラメータを持っています。\n",
    "\n",
    "ゲートされたショートカットが「クローズ」（ゼロに近づく）すると、ハイウェイネットワークのレイヤーは非残余関数を表します。\n",
    "\n",
    "逆に、我々の定式化は常に残余関数を学習する。アイデンティティのショートカットは決して閉じられず、すべての情報が常に通過し、追加の残余関数が学習されます。\n",
    "\n",
    "加えて、ハイウェイネットワークは、深度が非常に深く（例えば、100以上の層）、精度が向上していない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Deep Residual Learning\n",
    "\n",
    "### 3.1.Residual Learning\n",
    "\n",
    "いくつかの積み重ねられたレイヤー（必ずしもネット全体ではない）にフィットする基本的なマッピングとしてH（x）を考えてみましょう。\n",
    "\n",
    "xはこれらのレイヤーの最初のものへの入力を示します。\n",
    "\n",
    "複数の非線形層が複雑な関数を漸近的に近似できると仮定すると、\n",
    "\n",
    "残差関数、すなわちH（x）-x（入力と出力が同じ次元であると仮定して）を漸近的に近似できると仮定することと等価である。\n",
    "\n",
    "したがって、積み重ねられた層がH（x）を近似することを期待するのではなく、これらの層を残差関数F（x）：= H（x）-xに近似させる。\n",
    "\n",
    "従って元の関数はF（x）+ xとなる。\n",
    "\n",
    "両方の形式は、漸近的に（仮定されているように）所望の関数を近似することができなければならないが、学習の容易さは異なる可能性がある。\n",
    "\n",
    "この再定式化は、劣化問題の直観的な現象によって動機づけられる（図1左）。\n",
    "\n",
    "冒頭で議論したように、追加されたレイヤーをアイデンティティマッピングとして構築することができれば、より深いモデルのほうが浅いモデルほどトレーニングエラーが大きくなるはずです。\n",
    "\n",
    "分解の問題は、ソルバーが複数の非線形レイヤーによるアイデンティティマッピングを近似することが困難であることを示唆しています。\n",
    "\n",
    "残余学習再構成では、アイデンティティマッピングが最適である場合、ソルバは、アイデンティティマッピングに近づくために、複数の非線形レイヤの重みをゼロに向かって単純に駆動することができる。\n",
    "\n",
    "実際には、アイデンティティマッピングが最適であるとは考えにくいが、我々の再定式化は問題を前提条件とするのに役立つかもしれない。\n",
    "\n",
    "最適な関数がゼロ写像よりもアイデンティティ写像に近い場合、ソルバは新しい写像としての写像よりもアイデンティティ写像を参照して摂動を見つけやすくなります。\n",
    "\n",
    "学習された残差関数は一般的に小さな応答しか持たないことが実験によって示されており、アイデンティティマッピングが合理的な前処理を提供することを示唆している。\n",
    "\n",
    "### 3.2.Identity Mapping by Shortcuts\n",
    "\n",
    "いくつかの積み重ねたレイヤーごとに残差学習を採用しています。\n",
    "\n",
    "ビルディングブロックを図2に示します。正式には、この論文では、次のように定義されるビルディングブロックを考えます。ここで、xとyは、考慮するレイヤの入力と出力のベクトルです。\n",
    "\n",
    "関数F（x、{Wi}）は、学習すべき残差写像を表す。\n",
    "\n",
    "図2の例では、2つの層があり、F =W2σ（W1x）であり、σがReLU [29]を示し、バイアスを省略して表記を簡略化しています。\n",
    "\n",
    "操作F + xは、ショートカット接続および要素単位の加算によって実行されます。\n",
    "\n",
    "加算後の第2の非線形性（すなわち、σ（y）、図2参照）を採用する。\n",
    "\n",
    "方程式（1）のショートカット接続は余分なパラメータも計算の複雑さも導入しない。\n",
    "\n",
    "これは、実際には魅力的であるだけでなく、単純ネットワークと残余ネットワークの比較においても重要です。\n",
    "\n",
    "同じ数のパラメータ、深さ、幅、および計算コスト（無視できる要素ごとの加算を除いて）を同時に有するプレーン/残差ネットワークを公平に比較​​することができる。\n",
    "式（1）において、xとFの次元は等しくなければならない。\n",
    "\n",
    "これが当てはまらない場合（例えば、入出力チャネルを変更する場合）、次元を適合させるためにショートカット接続によって線形射影Wsを実行することができる。\n",
    "\n",
    "式（1）の正方行列Wsを使用することもできる。\n",
    "\n",
    "しかし、我々は、アイデンティティマッピングが劣化問題に対処するのに十分であり、経済的であることを実験によって示すので、Wsは次元を一致させるときにのみ使用される。\n",
    "\n",
    "残余関数Fの形は柔軟である。\n",
    "\n",
    "この論文の実験は、2つまたは3つの層（図5）を有する関数Fを含み、より多くの層が可能である。\n",
    "\n",
    "しかし、Fが単一の層しか有さない場合、方程式（1）は線形層に類似している：y = W1x + x。\n",
    "\n",
    "上記の表記は、単純化のため完全に接続されたレイヤーについてのものですが、畳み込みレイヤーにも適用できます。\n",
    "\n",
    "関数F（x、{Wi}）は、複数の畳み込み層を表すことができる。\n",
    "\n",
    "要素ごとの加算は、チャンネルごとに2つの特徴マップ上で実行される。\n",
    "\n",
    "### 3.3. Network Architectures\n",
    "\n",
    "我々は様々な平野/残存ネットをテストし、一貫した現象を観察した。\n",
    "\n",
    "ディスカッションのためのインスタンスを提供するために、ImageNetの2つのモデルを以下に説明します。\n",
    "\n",
    "#### Plain Network.\n",
    "\n",
    "私たちのプレーンベースライン（図3、中央）は、主にVGGネットの哲学に基づいています（図3、左）。\n",
    "\n",
    "畳み込みレイヤは主に3×3のフィルタを持ち、2つのシンプルなデザインルールに従います。\n",
    "\n",
    "（i）同じ出力フィーチャマップサイズの場合、レイヤは同じ数のフィルタを持ちます。 \n",
    "\n",
    "（ii）フィーチャマップサイズが半分の場合、フィルタの数は、レイヤごとの時間複雑さを保つために2倍になる。\n",
    "\n",
    "我々は、2のストライドを有する畳み込みレイヤーによって直接ダウンサンプリングを実行する。\n",
    "\n",
    "ネットワークは、グローバル平均プール層とsoftmaxを備えた1000ウェイ完全接続層で終わります。\n",
    "\n",
    "重み付けされた層の総数は、図3（中）の34である。\n",
    "\n",
    "我々のモデルがVGGネットよりも少ないフィルタと複雑さを持つことに気付く価値がある[41]（図3左）。\n",
    "\n",
    "当社の34層ベースラインは、VGG-19（196億FLOPs）の18％に過ぎない36億FLOP（多重加算）を有している。\n",
    "\n",
    "#### Residual Network.\n",
    "\n",
    "上記の単純なネットワークに基づいて、ネットワークを対応する残りのバージョンにするショートカット接続を挿入します（図3右）。\n",
    "\n",
    "アイデンティティ・ショートカット（方程式（1））は、入力と出力が同じ次元の場合に直接使用することができます（図3の実線のショートカット）。\n",
    "\n",
    "（A）ショートカットは依然としてアイデンティティマッピングを実行し、増加する次元のために余分なゼロエントリが埋め込まれています（図3の点線のショートカット）。\n",
    "このオプションは余分なパラメータを導入しません。\n",
    "\n",
    "（B）式（2）の投影ショートカットは、（1×1の畳み込みによって行われる）次元を一致させるために使用される。\n",
    "\n",
    "両方のオプションについて、ショートカットが2つのサイズのフィーチャマップを横断するとき、ショートカットは2のストライドで実行されます。\n",
    "\n",
    "### 3.4.Implementation\n",
    "\n",
    "ImageNetの実装は、[21、41]の習慣に従います。\n",
    "\n",
    "拡大縮小のために、画像の短辺を[256、480]で無作為にサンプリングしてサイズ変更します[41]。\n",
    "\n",
    "224×224のクロップは、画像またはその水平フリップから無作為にサンプリングされ、ピクセルごとの平均が減算される[21]。\n",
    "\n",
    "[21]の標準的な色の増強が使用されます。\n",
    "\n",
    "我々は[16]に続いて、各畳み込みの直後で活性化の前に、バッチ標準化（BN）[16]を採用する。\n",
    "\n",
    "我々は[13]のように重みを初期化し、全てのプレーン/残差ネットをゼロから訓練する。\n",
    "\n",
    "256のミニバッチサイズのSGDを使用します。\n",
    "\n",
    "学習率は0.1から始まり、エラーがプラトーになったときに10で除算され、モデルは60×104反復までトレーニングされます。\n",
    "\n",
    "0.0001の重量減と0.9の運動量を使用します。\n",
    "\n",
    "私たちは[16]の習慣に従ったドロップアウト[14]を使用していません。\n",
    "\n",
    "テストでは、比較研究のために標準的な10作物テストを採用しています[21]。\n",
    "\n",
    "最良の結果を得るには、[41、13]のように完全畳み込み式を採用し、複数のスケールで平均を取る（画像の長さが{224,256,384,480,640}になるように画像のサイズを変更する）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4.Experiments\n",
    "\n",
    "### 4.1.ImageNet Classification\n",
    "\n",
    "我々は、1000のクラスからなるImageNet 2012分類データセット[36]上で我々の方法を評価する。\n",
    "\n",
    "モデルは1.28百万のトレーニング画像で訓練され、50kの検証画像で評価されます。\n",
    "\n",
    "また、テストサーバーによって報告された100kテストイメージの最終結果も取得します。\n",
    "\n",
    "私たちは、トップ1エラーとトップ5エラーの両方のエラーレートを評価します。\n",
    "\n",
    "#### Plain Networks.\n",
    "\n",
    "最初に、18層および34層のプレーンネットを評価します。\n",
    "\n",
    "34層のプレーンネットは図3（中央）にあります。\n",
    "\n",
    "18層のプレーンネットも同様の形式です。\n",
    "\n",
    "詳細なアーキテクチャについては、表1を参照してください。\n",
    "\n",
    "表2の結果は、より深い34層プレーンネットは、より浅い18層プレーンネットよりも高い検証エラーを有することを示している。\n",
    "\n",
    "理由を明らかにするために、図4（左）では、訓練手順中の訓練/妥当性の誤りを比較する。\n",
    "\n",
    "我々は、18層プレーンネットワークの解空間が34層ネットワークの解空間の部分空間であるにもかかわらず、34層プレーンネットはトレーニング手順全体を通じてより高いトレーニングエラーを有するという劣化問題を観察した。\n",
    "\n",
    "この最適化の難しさは、勾配の消失によって引き起こされる可能性は低いと主張している。\n",
    "\n",
    "これらの単純なネットワークはBN [16]で訓練されており、順方向に伝搬された信号の分散がゼロでないことが保証されます。\n",
    "\n",
    "我々はまた、逆伝播勾配がBNで健康的な基準を示すことを確認する。\n",
    "\n",
    "したがって、順方向信号も逆方向信号も消滅しない。\n",
    "\n",
    "実際、34層プレーンネットは依然として競争の精度を達成することができ（表3）、ソルバーがある程度機能することを示唆しています。\n",
    "\n",
    "我々は、深い平野のネットが指数関数的に低い収束速度を持ち、訓練誤差の低減に影響を与える可能性があると推測している3。\n",
    "\n",
    "このような最適化の難しさの理由については今後検討する予定である。\n",
    "\n",
    "#### Residual Networks.\n",
    "\n",
    "次に、18層および34層の残差ネット（ResNets）を評価します。\n",
    "\n",
    "ベースラインのアーキテクチャは上記のプレーンネットと同じですが、図3（右）のように3×3フィルタの各ペアにショートカット接続が追加されることが予想されます。\n",
    "\n",
    "最初の比較（表2および図4の右）では、すべてのショートカットに対してアイデンティティマッピングを使用し、次元を増やすためにゼロパディング（オプションA）を使用します。\n",
    "\n",
    "したがって、彼らはプレーンな部分に比べて余分なパラメータを持っていません。\n",
    "\n",
    "表2と図4の3つの主要な観察結果があります。\n",
    "\n",
    "第1に、残りの学習で状況が逆転します.34層のResNetは18層のResNetよりも優れています（2.8％）。\n",
    "\n",
    "さらに重要なことには、34層のResNetはかなり低いトレーニングエラーを示し、検証データに一般化することができます。\n",
    "\n",
    "これは、この設定では劣化問題がうまく対処されており、深さが深くなると精度が向上することを示しています。\n",
    "\n",
    "第2に、34層esNetは、正常なトレーニングエラー（図4の右と左）が成功した結果、上位1のエラーを3.5％削減します（表2）。\n",
    "\n",
    "この比較は、非常に深いシステムでの残存学習の有効性を検証します。\n",
    "\n",
    "最後に、18層のプレーン/リジッドネットは比較的正確です（表2）が、18層のResNetはより高速に収束します（図4の右側左）。\n",
    "\n",
    "ネットが \"あまり深くない\"場合（ここでは18層）、現在のSGDソルバーはまだプレーンネットに良い解決策を見つけることができます。\n",
    "\n",
    "この場合、ResNetは初期の段階でより早くコンバージェンスを提供することによって最適化を容易にします。\n",
    "\n",
    "#### Identity vs. Projection Shortcuts.\n",
    "\n",
    "パラメータのない身元確認のショートカットがトレーニングに役立つことを示しました。\n",
    "\n",
    "次に、投影ショートカット（式（2））を調べる。\n",
    "\n",
    "表3では、3つのオプションを比較します。\n",
    "\n",
    "（A）ゼロパディングショートカットはディメンションの増加に使用され、すべてのショートカットはパラメータフリーです（表2および図4の右と同じ）。 \n",
    "\n",
    "（B）投影ショートカットは寸法を大きくするために使用され、他のショートカットは同一性があります。 \n",
    "\n",
    "（C）すべてのショートカットは投影です。\n",
    "\n",
    "表3は、3つの選択肢全てが平易なものよりもかなり優れていることを示している。\n",
    "BはAよりわずかに優れています。\n",
    "\n",
    "これは、Aのゼロ埋め込みディメンションが実際には残余学習を持たないためであると主張する。\n",
    "\n",
    "CはBよりわずかに優れており、これを多くの（13個の）投影ショートカットによって導入された余分なパラメータとみなしています。\n",
    "\n",
    "しかし、A / B / Cの小さな違いは、投影のショートカットが劣化の問題に対処するために不可欠ではないことを示しています。\n",
    "\n",
    "したがって、メモリ/時間の複雑さとモデルサイズを減らすために、このホワイトペーパーの残りの部分ではオプションCを使用しません。\n",
    "\n",
    "アイデンティティ・ショートカットは、以下で紹介するボトルネック・アーキテクチャーの複雑さを増やさないために特に重要です。\n",
    "\n",
    "#### Deeper Bottleneck Architectures.\n",
    "\n",
    "次に、ImageNetの深いネットについて説明します。\n",
    "\n",
    "私たちが手に入れることができるトレーニング時間に懸念があるため、ビルディングブロックをボトルネックの設計として修正します4。\n",
    "\n",
    "各残余関数Fについて、2の代わりに3つの層のスタックを使用する（図5）。\n",
    "\n",
    "3つの層は、1×1、3×3、および1×1の畳み込みであり、1×1層は寸法を縮小してから増加させ（復元する）、3×3層は入力/出力の寸法が小さい 。\n",
    "\n",
    "図5は、両方の設計が同様の時間の複雑さを有する例を示す。\n",
    "\n",
    "パラメータのないアイデンティティ・ショートカットは、ボトルネック・アーキテクチャにとって特に重要です。\n",
    "\n",
    "図5のアイデンティティ・ショートカット（右）を投影に置き換えると、ショートカットが2つの高次元の端に接続されているため、時間の複雑さとモデルのサイズが2倍になっていることがわかります。\n",
    "\n",
    "したがって、アイデンティティのショートカットは、ボトルネックの設計のためのより効率的なモデルにつながります。\n",
    "\n",
    "##### 50-layer ResNet:\n",
    "\n",
    "34層ネットの各2層ブロックをこの3層ボトルネックブロックに置き換え、50層のResNet（表1）を作成しました。\n",
    "\n",
    "次元を増やすためにオプションBを使用します。\n",
    "このモデルは38億FLOPsです。\n",
    "\n",
    "##### 101-layer and 152-layer ResNets:\n",
    "\n",
    "我々は、より多くの3層ブロックを使用して101層および152層のResNetsを構築する（表1）。\n",
    "\n",
    "注目すべきことに、深さは大幅に増えるが、152層のResNet（113億FLOPs）は、VGG-16/19ネット（15.3 / 196億FLOPs）よりも複雑さが低い。\n",
    "\n",
    "50/101/152レイヤーのResNetは、34マスのResNetsよりもかなりのマージンで正確です（表3と4）。\n",
    "\n",
    "劣化の問題は観測されず、深度が大幅に増加しても精度が大幅に向上します。\n",
    "深さの利点は、すべての評価指標で目撃されています（表3と表4）。\n",
    "\n",
    "#### Comparisons with State-of-the-art Methods.\n",
    "\n",
    "表4では、これまでの最良の単一モデルの結果と比較しています。\n",
    "\n",
    "当社のベースライン34層ResNetsは非常に競争の激しい精度を達成しています。\n",
    "\n",
    "当社の152層のResNetは、単一モデルのトップ5検証エラーが4.49％です。\n",
    "\n",
    "この単一モデルの結果は、以前のすべてのアンサンブル結果よりも優れています（表5）。\n",
    "\n",
    "我々はアンサンブルを形成するために異なる深さの6つのモデルを組み合わせる（提出時には2つの152層のもののみとする）。\n",
    "\n",
    "これにより、テストセットで3.57％のトップ5エラーが発生します（表5）。\n",
    "\n",
    "このエントリーはILSVRC 2015の第1位を獲得しました。\n",
    "\n",
    "### 4.2.CIFAR-10 and Analysis\n",
    "\n",
    "CIFAR-10データセット[20]は、50kのトレーニング画像と10kテスト画像の10クラスで構成されています。\n",
    "\n",
    "訓練セットで訓練された実験を提示し、テストセットで評価する。\n",
    "\n",
    "私たちは非常に深いネットワークの振る舞いに焦点を絞っていますが、最先端の結果を押し進めるのではなく、意図的に以下のような単純なアーキテクチャを使用しています。\n",
    "\n",
    "単純/残余のアーキテクチャは、図3の形式（中央/右）に従います。\n",
    "\n",
    "ネットワーク入力は、32×32画像であり、ピクセルごとの平均を引いたものである。第1の層は3×3畳み込みである。\n",
    "\n",
    "次に、サイズが{32,16,8}のフィーチャマップ上にそれぞれ3×3コンボリューションの6nレイヤのスタックを使用し、フィーチャマップサイズごとに2nレイヤを使用します。\n",
    "\n",
    "フィルタの数はそれぞれ{16,32,64}です。\n",
    "\n",
    "サブサンプリングは、2のストライドを有する畳み込みによって実行される。\n",
    "\n",
    "ネットワークは、グローバル平均プール、10方向完全接続レイヤー、およびsoftmaxで終わります。\n",
    "全部で6n + 2の積重ねられた層がある。\n",
    "\n",
    "次の表に、アーキテクチャの概要を示します。ショートカット接続を使用する場合、それらは3×3レイヤーのペア（合計3n個のショートカット）に接続されます。\n",
    "\n",
    "このデータセットでは、すべてのケースでアイデンティティショートカット（オプションA）を使用しているため、残りのモデルは、プレーンな部分とまったく同じ深度、幅、およびパラメータの数を持っています。\n",
    "\n",
    "0.0001の重み減と0.9の運動量を使用し、[13]とBN [16]の重みの初期化を採用しますが、ドロップアウトはありません。\n",
    "\n",
    "これらのモデルは、2つのGPUで128のミニサイズでトレーニングされています。\n",
    "\n",
    "まず、学習率0.1で32kと48kの繰り返しで10で除算し、45k / 5kの列/ val分割で決定される64k回の反復で終了します。\n",
    "\n",
    "トレーニングでは、[24]の単純なデータ補強に従います.4つのピクセルが各面にパディングされ、32×32クロップがパディングされたイメージまたはその水平フリップからランダムにサンプリングされます。\n",
    "\n",
    "テストのために、オリジナルの32×32イメージの単一のビューのみを評価します。\n",
    "n = {3,5,7,9}を比較すると、20,32,44、および56層のネットワークにつながります。\n",
    "\n",
    "図6（左）は平野ネットの挙動を示す。\n",
    "\n",
    "ディーププレーンネットは深さが深く、深く進むとトレーニングエラーが高くなります。\n",
    "\n",
    "この現象はImageNet（図4左）とMNIST（[42]参照）と同様であり、このような最適化の難しさは基本的な問題であることを示唆している。\n",
    "\n",
    "図6（中央）はResNetsの動作を示している。\n",
    "\n",
    "また、ImageNetのケース（図4右）と同様に、ResNetsは最適化の難しさを克服し、深度が増すと精度を上げることができます。\n",
    "\n",
    "私たちはさらに、110層のResNetにつながるn = 18を探索します。\n",
    "\n",
    "この場合、最初の学習率0.1は、収束を開始するにはわずかに大きすぎます5。\n",
    "\n",
    "したがって、トレーニングエラーが80％（約400回の反復）未満になるまで0.01を使用し、0.1に戻ってトレーニングを続けます。\n",
    "\n",
    "残りの学習スケジュールは以前と同じです。\n",
    "\n",
    "この110層のネットワークはうまく収束します（図6、中央）。\n",
    "\n",
    "FitNet [35]やHighway [42]（表6）などの他の深くて薄いネットワークに比べてパラメータは少なく、最先端の結果（6.43％、表6）です。\n",
    "\n",
    "#### Analysis of Layer Responses.\n",
    "\n",
    "図7は、層応答の標準偏差（std）を示す。\n",
    "\n",
    "応答は、BN後および他の非線形性（ReLU /加算）の前に、各3×3層の出力である。\n",
    "\n",
    "ResNetsの場合、この分析は残留関数の応答強度を示します。\n",
    "\n",
    "図7に示すように、ResNetsは一般的にレスポンスがレスポンスよりも小さいことがわかります。\n",
    "\n",
    "これらの結果は、残余関数が非残余関数より一般にゼロに近い可能性があるという我々の基本的なモチベーション（Sec.3.1）を支持する。\n",
    "\n",
    "また、図7のResNet-20,56、および110の比較からもわかるように、より深いResNetの応答の方が小さいことがわかります。\n",
    "\n",
    "より多くのレイヤーがある場合、ResNetsの個々のレイヤーは信号をあまり変更しません。\n",
    "\n",
    "#### Exploring Over 1000 layers.\n",
    "\n",
    "私たちは、1000以上のレイヤーの積極的な深いモデルを探求します。\n",
    "\n",
    "我々は、上記のように訓練された1202層のネットワークにつながるn = 200を設定する。\n",
    "\n",
    "我々の方法は最適化の困難さを示さず、この103層ネットワークはトレーニング誤差<0.1％を達成することができる（図6右）。\n",
    "\n",
    "そのテストエラーはまだかなり良いです（7.93％、表6）。\n",
    "\n",
    "しかし、このような積極的な深いモデルにはまだ未解決の問題があります。\n",
    "\n",
    "この1202レイヤーネットワークのテスト結果は、110レイヤーネットワークのテスト結果よりも悪いですが、どちらも同様のトレーニングエラーがあります。\n",
    "\n",
    "これはオーバーフィッティングのためだと主張する。\n",
    "\n",
    "この小さなデータセットでは、1202層のネットワークが不必要に大きくなる可能性があります（19.4M）。\n",
    "\n",
    "maxout [10]やdropout [14]のような強力な正則化が適用され、このデータセットで最良の結果（[10,25,24,35]）が得られます。\n",
    "\n",
    "本稿ではmaxout / dropoutを使用せず、最適化の難しさに焦点を当てることなく、深くて薄いアーキテクチャーによるデザインによる正則化を単純に課すだけです。\n",
    "\n",
    "しかし、正式化を強化することで結果を改善することができます。これについては今後検討します。\n",
    "\n",
    "### 4.3.Object Detection on PASCAL and MS COCO\n",
    "\n",
    "我々の方法は、他の認識タスクに対して良好な汎化性能を有する。\n",
    "\n",
    "表7と8は、PASCAL VOC 2007と2012 [5]とCOCO [26]のオブジェクト検出ベースラインの結果を示しています。\n",
    "\n",
    "我々は検出方法としてFaster R-CNN [32]を採用する。\n",
    "\n",
    "ここでは、VGG-16 [41]をResNet-101に置き換えることの改善に興味があります。\n",
    "\n",
    "両方のモデルを使用する検出の実装（付録を参照）は同じであるため、利益はより良いネットワークに起因するだけです。\n",
    "\n",
    "最も驚くべきことに、挑戦的なCOCOデータセットでは、COCOの標準メトリック（mAP @ [.5、.95]）が6.0％増加します。これは28％の相対的改善です。\n",
    "\n",
    "この利得は、学習された表現によるものです。\n",
    "\n",
    "深い残存ネットに基づいて、ILSVRC＆COCO 2015競技会では、ImageNet検出、ImageNetローカリゼーション、COCO検出、およびCOCOセグメンテーションの各トラ\n",
    "ックで1位を獲得しました。\n",
    "\n",
    "詳細は付録にあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
